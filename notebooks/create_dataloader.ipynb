{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc715cf",
   "metadata": {},
   "source": [
    "# Cleaning Data and Creating DataLoader Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad075ef",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34672e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from importlib.metadata import version\n",
    "from logging import Logger\n",
    "from typing import List, Optional\n",
    "import logging\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db165c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6886c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:pandas version: 2.3.2\n",
      "INFO:__main__:importlib-metadata version: 8.7.0\n",
      "INFO:__main__:pyarrow version: 21.0.0\n"
     ]
    }
   ],
   "source": [
    "packages = [\"pandas\", \"importlib-metadata\", \"pyarrow\"]\n",
    "for package in packages:\n",
    "    try:\n",
    "        logger.info(f\"{package} version: {version(package)}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not get version for package {package}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040322d",
   "metadata": {},
   "source": [
    "## Load Dataframe from csv file in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c642d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../Data\")\n",
    "RAW_DATA_DIR_NAME = \"Downloaded-Data\"\n",
    "\n",
    "DATA_RAW_FILE_NAME = \"data-RAW.csv\"\n",
    "DATA_CLEAN_FILE_NAME = \"data-CLEAN.csv\"\n",
    "\n",
    "RAW_DATA_PATH = DATA_ROOT / RAW_DATA_DIR_NAME / DATA_RAW_FILE_NAME\n",
    "DATA_PATH = DATA_ROOT / RAW_DATA_DIR_NAME / DATA_CLEAN_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2d47ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50211765",
   "metadata": {},
   "source": [
    "## Practicing Data Cleaning and Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631a6e8",
   "metadata": {},
   "source": [
    "### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3845851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_these = [\n",
    "    \"diet_score\",\n",
    "    \"age_group\",\n",
    "    \"bmi_whr_group\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "17112664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=drop_these, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6bfe17",
   "metadata": {},
   "source": [
    "### Filling in NaN entries, if Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3e10466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"alcohol_group\"] = df[\"alcohol_group\"].fillna(\"Light\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3604cf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'ethnicity', 'education_level', 'income_level',\n",
       "       'employment_status', 'smoking_status', 'alcohol_consumption_per_week',\n",
       "       'physical_activity_minutes_per_week', 'sleep_hours_per_day',\n",
       "       'screen_time_hours_per_day', 'family_history_diabetes',\n",
       "       'hypertension_history', 'cardiovascular_history', 'bmi',\n",
       "       'waist_to_hip_ratio', 'systolic_bp', 'diastolic_bp', 'heart_rate',\n",
       "       'cholesterol_total', 'hdl_cholesterol', 'ldl_cholesterol',\n",
       "       'triglycerides', 'glucose_fasting', 'glucose_postprandial',\n",
       "       'insulin_level', 'hba1c', 'diabetes_risk_score', 'diabetes_stage',\n",
       "       'diagnosed_diabetes', 'abdominal_obesity', 'bmi_group',\n",
       "       'activity_level', 'alcohol_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ee99efe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 34)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34a12bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  int64  \n",
      " 1   gender                              100000 non-null  object \n",
      " 2   ethnicity                           100000 non-null  object \n",
      " 3   education_level                     100000 non-null  object \n",
      " 4   income_level                        100000 non-null  object \n",
      " 5   employment_status                   100000 non-null  object \n",
      " 6   smoking_status                      100000 non-null  object \n",
      " 7   alcohol_consumption_per_week        100000 non-null  int64  \n",
      " 8   physical_activity_minutes_per_week  100000 non-null  int64  \n",
      " 9   sleep_hours_per_day                 100000 non-null  float64\n",
      " 10  screen_time_hours_per_day           100000 non-null  float64\n",
      " 11  family_history_diabetes             100000 non-null  int64  \n",
      " 12  hypertension_history                100000 non-null  int64  \n",
      " 13  cardiovascular_history              100000 non-null  int64  \n",
      " 14  bmi                                 100000 non-null  float64\n",
      " 15  waist_to_hip_ratio                  100000 non-null  float64\n",
      " 16  systolic_bp                         100000 non-null  int64  \n",
      " 17  diastolic_bp                        100000 non-null  int64  \n",
      " 18  heart_rate                          100000 non-null  int64  \n",
      " 19  cholesterol_total                   100000 non-null  int64  \n",
      " 20  hdl_cholesterol                     100000 non-null  int64  \n",
      " 21  ldl_cholesterol                     100000 non-null  int64  \n",
      " 22  triglycerides                       100000 non-null  int64  \n",
      " 23  glucose_fasting                     100000 non-null  int64  \n",
      " 24  glucose_postprandial                100000 non-null  int64  \n",
      " 25  insulin_level                       100000 non-null  float64\n",
      " 26  hba1c                               100000 non-null  float64\n",
      " 27  diabetes_risk_score                 100000 non-null  float64\n",
      " 28  diabetes_stage                      100000 non-null  object \n",
      " 29  diagnosed_diabetes                  100000 non-null  int64  \n",
      " 30  abdominal_obesity                   100000 non-null  int64  \n",
      " 31  bmi_group                           100000 non-null  object \n",
      " 32  activity_level                      100000 non-null  object \n",
      " 33  alcohol_group                       86465 non-null   object \n",
      "dtypes: float64(7), int64(17), object(10)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3899cfb",
   "metadata": {},
   "source": [
    "### Create Dictionaries for Encoding/Mapping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f39d9",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e029de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = sorted(df[\"gender\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {gender: float(idx) for idx, gender in enumerate(genders)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a85d7a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Female': 0, 'Male': 1, 'Other': 2}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4136de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicities = sorted(df[\"ethnicity\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2663e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_dict = {ethnicity: float(idx) for idx, ethnicity in enumerate(ethnicities)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e167659d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Asian': 0.0, 'Black': 1.0, 'Hispanic': 2.0, 'Other': 3.0, 'White': 4.0}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "243bf427",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_levels = sorted(df[\"education_level\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f245661",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_level_dict = {education_level: float(idx) for idx, education_level in enumerate(education_levels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f28ce1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Graduate': 0.0, 'Highschool': 1.0, 'No formal': 2.0, 'Postgraduate': 3.0}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fbd1b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_levels = sorted(df[\"income_level\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9ea1752",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_level_dict = {income_level: float(idx) for idx, income_level in enumerate(income_levels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0832d414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'High': 0.0,\n",
       " 'Low': 1.0,\n",
       " 'Lower-Middle': 2.0,\n",
       " 'Middle': 3.0,\n",
       " 'Upper-Middle': 4.0}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "725c568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_statuses = sorted(df[\"employment_status\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6bd56cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_status_dict = {employment_status: float(idx) for idx, employment_status in enumerate(employment_statuses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d758900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Employed': 0.0, 'Retired': 1.0, 'Student': 2.0, 'Unemployed': 3.0}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_status_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "21e3caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_statuses = sorted(df[\"smoking_status\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "552c9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_status_dict = {smoking_status: float(idx) for idx, smoking_status in enumerate(smoking_statuses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9e3b338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Current': 0.0, 'Former': 1.0, 'Never': 2.0}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoking_status_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7d1d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_stages = sorted(df[\"diabetes_stage\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "593f90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_stage_dict = {diabetes_stage: float(idx) for idx, diabetes_stage in enumerate(diabetes_stages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b48f5a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gestational': 0.0,\n",
       " 'No Diabetes': 1.0,\n",
       " 'Pre-Diabetes': 2.0,\n",
       " 'Type 1': 3.0,\n",
       " 'Type 2': 4.0}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_stage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c7f0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_groups = sorted(df[\"bmi_group\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "528fc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_group_dict = {bmi_group: float(idx) for idx, bmi_group in enumerate(bmi_groups)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "335e676a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0.0, 'Obese': 1.0, 'Overweight': 2.0, 'Underweight': 3.0}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi_group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bad563dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_levels = sorted(df[\"activity_level\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81ce6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_level_dict = {activity_level: float(idx) for idx, activity_level in enumerate(activity_levels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "69aab576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'High': 0.0, 'Low': 1.0, 'Moderate': 2.0}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity_level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ae694bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_groups = sorted(df[\"alcohol_group\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3d53bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_group_dict = {alcohol_group: float(idx) for idx, alcohol_group in enumerate(alcohol_groups)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "236b9fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Heavy': 0.0, 'Light': 1.0, 'Moderate': 2.0}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol_group_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e33f975",
   "metadata": {},
   "source": [
    "### Apply Encoding/Mapping to the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "93f0aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gender\"] = df[\"gender\"].map(gender_dict)\n",
    "df[\"ethnicity\"] = df[\"ethnicity\"].map(ethnicity_dict)\n",
    "df[\"education_level\"] = df[\"education_level\"].map(education_level_dict)\n",
    "df[\"income_level\"] = df[\"income_level\"].map(income_level_dict)\n",
    "df[\"employment_status\"] = df[\"employment_status\"].map(employment_status_dict)\n",
    "df[\"smoking_status\"] = df[\"smoking_status\"].map(smoking_status_dict)\n",
    "df[\"diabetes_stage\"] = df[\"diabetes_stage\"].map(diabetes_stage_dict)\n",
    "df[\"bmi_group\"] = df[\"bmi_group\"].map(bmi_group_dict)\n",
    "df[\"activity_level\"] = df[\"activity_level\"].map(activity_level_dict)\n",
    "df[\"alcohol_group\"] = df[\"alcohol_group\"].map(alcohol_group_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998fc61",
   "metadata": {},
   "source": [
    "### Check the new datatypes to make sure all string objects are converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b90bd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                     int64\n",
       "gender                                  int64\n",
       "ethnicity                             float64\n",
       "education_level                       float64\n",
       "income_level                          float64\n",
       "employment_status                     float64\n",
       "smoking_status                        float64\n",
       "alcohol_consumption_per_week            int64\n",
       "physical_activity_minutes_per_week      int64\n",
       "sleep_hours_per_day                   float64\n",
       "screen_time_hours_per_day             float64\n",
       "family_history_diabetes                 int64\n",
       "hypertension_history                    int64\n",
       "cardiovascular_history                  int64\n",
       "bmi                                   float64\n",
       "waist_to_hip_ratio                    float64\n",
       "systolic_bp                             int64\n",
       "diastolic_bp                            int64\n",
       "heart_rate                              int64\n",
       "cholesterol_total                       int64\n",
       "hdl_cholesterol                         int64\n",
       "ldl_cholesterol                         int64\n",
       "triglycerides                           int64\n",
       "glucose_fasting                         int64\n",
       "glucose_postprandial                    int64\n",
       "insulin_level                         float64\n",
       "hba1c                                 float64\n",
       "diabetes_risk_score                   float64\n",
       "diabetes_stage                        float64\n",
       "diagnosed_diabetes                      int64\n",
       "abdominal_obesity                       int64\n",
       "bmi_group                             float64\n",
       "activity_level                        float64\n",
       "alcohol_group                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b641d6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk_score</th>\n",
       "      <th>diabetes_stage</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "      <th>abdominal_obesity</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>alcohol_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  ethnicity  education_level  income_level  employment_status  \\\n",
       "0  58.0     1.0        0.0              1.0           2.0                0.0   \n",
       "1  48.0     0.0        4.0              1.0           3.0                0.0   \n",
       "2  60.0     1.0        2.0              1.0           3.0                3.0   \n",
       "3  74.0     0.0        1.0              1.0           1.0                1.0   \n",
       "4  46.0     1.0        4.0              0.0           3.0                1.0   \n",
       "\n",
       "   smoking_status  alcohol_consumption_per_week  \\\n",
       "0             2.0                           0.0   \n",
       "1             1.0                           1.0   \n",
       "2             2.0                           1.0   \n",
       "3             2.0                           0.0   \n",
       "4             2.0                           1.0   \n",
       "\n",
       "   physical_activity_minutes_per_week  sleep_hours_per_day  ...  \\\n",
       "0                               215.0                  7.9  ...   \n",
       "1                               143.0                  6.5  ...   \n",
       "2                                57.0                 10.0  ...   \n",
       "3                                49.0                  6.6  ...   \n",
       "4                               109.0                  7.4  ...   \n",
       "\n",
       "   glucose_postprandial  insulin_level  hba1c  diabetes_risk_score  \\\n",
       "0                 236.0           6.36   8.18            29.600000   \n",
       "1                 150.0           2.00   5.63            23.000000   \n",
       "2                 195.0           5.07   7.51            44.700001   \n",
       "3                 253.0           5.28   9.03            38.200001   \n",
       "4                 184.0          12.74   7.20            23.500000   \n",
       "\n",
       "   diabetes_stage  diagnosed_diabetes  abdominal_obesity  bmi_group  \\\n",
       "0             4.0                 1.0                0.0        1.0   \n",
       "1             1.0                 0.0                0.0        0.0   \n",
       "2             4.0                 1.0                0.0        0.0   \n",
       "3             4.0                 1.0                1.0        2.0   \n",
       "4             4.0                 1.0                0.0        0.0   \n",
       "\n",
       "   activity_level  alcohol_group  \n",
       "0             0.0            1.0  \n",
       "1             2.0            1.0  \n",
       "2             1.0            1.0  \n",
       "3             1.0            1.0  \n",
       "4             2.0            1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a0bbe05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"gender\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d71986",
   "metadata": {},
   "source": [
    "### Convert all columns into Specific datatypes\n",
    "* After conversion, it may produce NaNs. If so, try the whole process again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b80c7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068feac3",
   "metadata": {},
   "source": [
    "### Print details of the Final Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "afe78d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  float32\n",
      " 1   gender                              100000 non-null  float32\n",
      " 2   ethnicity                           100000 non-null  float32\n",
      " 3   education_level                     100000 non-null  float32\n",
      " 4   income_level                        100000 non-null  float32\n",
      " 5   employment_status                   100000 non-null  float32\n",
      " 6   smoking_status                      100000 non-null  float32\n",
      " 7   alcohol_consumption_per_week        100000 non-null  float32\n",
      " 8   physical_activity_minutes_per_week  100000 non-null  float32\n",
      " 9   sleep_hours_per_day                 100000 non-null  float32\n",
      " 10  screen_time_hours_per_day           100000 non-null  float32\n",
      " 11  family_history_diabetes             100000 non-null  float32\n",
      " 12  hypertension_history                100000 non-null  float32\n",
      " 13  cardiovascular_history              100000 non-null  float32\n",
      " 14  bmi                                 100000 non-null  float32\n",
      " 15  waist_to_hip_ratio                  100000 non-null  float32\n",
      " 16  systolic_bp                         100000 non-null  float32\n",
      " 17  diastolic_bp                        100000 non-null  float32\n",
      " 18  heart_rate                          100000 non-null  float32\n",
      " 19  cholesterol_total                   100000 non-null  float32\n",
      " 20  hdl_cholesterol                     100000 non-null  float32\n",
      " 21  ldl_cholesterol                     100000 non-null  float32\n",
      " 22  triglycerides                       100000 non-null  float32\n",
      " 23  glucose_fasting                     100000 non-null  float32\n",
      " 24  glucose_postprandial                100000 non-null  float32\n",
      " 25  insulin_level                       100000 non-null  float32\n",
      " 26  hba1c                               100000 non-null  float32\n",
      " 27  diabetes_risk_score                 100000 non-null  float32\n",
      " 28  diabetes_stage                      100000 non-null  float32\n",
      " 29  diagnosed_diabetes                  100000 non-null  float32\n",
      " 30  abdominal_obesity                   100000 non-null  float32\n",
      " 31  bmi_group                           100000 non-null  float32\n",
      " 32  activity_level                      100000 non-null  float32\n",
      " 33  alcohol_group                       100000 non-null  float32\n",
      "dtypes: float32(34)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942a60b",
   "metadata": {},
   "source": [
    "### End of Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4eae7b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk_score</th>\n",
       "      <th>diabetes_stage</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "      <th>abdominal_obesity</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>alcohol_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  ethnicity  education_level  income_level  employment_status  \\\n",
       "0  58.0     1.0        0.0              1.0           2.0                0.0   \n",
       "1  48.0     0.0        4.0              1.0           3.0                0.0   \n",
       "2  60.0     1.0        2.0              1.0           3.0                3.0   \n",
       "3  74.0     0.0        1.0              1.0           1.0                1.0   \n",
       "4  46.0     1.0        4.0              0.0           3.0                1.0   \n",
       "\n",
       "   smoking_status  alcohol_consumption_per_week  \\\n",
       "0             2.0                           0.0   \n",
       "1             1.0                           1.0   \n",
       "2             2.0                           1.0   \n",
       "3             2.0                           0.0   \n",
       "4             2.0                           1.0   \n",
       "\n",
       "   physical_activity_minutes_per_week  sleep_hours_per_day  ...  \\\n",
       "0                               215.0                  7.9  ...   \n",
       "1                               143.0                  6.5  ...   \n",
       "2                                57.0                 10.0  ...   \n",
       "3                                49.0                  6.6  ...   \n",
       "4                               109.0                  7.4  ...   \n",
       "\n",
       "   glucose_postprandial  insulin_level  hba1c  diabetes_risk_score  \\\n",
       "0                 236.0           6.36   8.18            29.600000   \n",
       "1                 150.0           2.00   5.63            23.000000   \n",
       "2                 195.0           5.07   7.51            44.700001   \n",
       "3                 253.0           5.28   9.03            38.200001   \n",
       "4                 184.0          12.74   7.20            23.500000   \n",
       "\n",
       "   diabetes_stage  diagnosed_diabetes  abdominal_obesity  bmi_group  \\\n",
       "0             4.0                 1.0                0.0        1.0   \n",
       "1             1.0                 0.0                0.0        0.0   \n",
       "2             4.0                 1.0                0.0        0.0   \n",
       "3             4.0                 1.0                1.0        2.0   \n",
       "4             4.0                 1.0                0.0        0.0   \n",
       "\n",
       "   activity_level  alcohol_group  \n",
       "0             0.0            1.0  \n",
       "1             2.0            1.0  \n",
       "2             1.0            1.0  \n",
       "3             1.0            1.0  \n",
       "4             2.0            1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59216d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify target column\n",
    "target_col = 'ENTER TARGET COLUMN HERE (e.g. Targets)'\n",
    "target_col = 'diagnosed_diabetes'\n",
    "\n",
    "# Get all columns except target\n",
    "cols = [col for col in df.columns if col != target_col]\n",
    "\n",
    "# Sort columns alphabetically\n",
    "sorted_cols = sorted(cols)\n",
    "\n",
    "# Add target column at the end\n",
    "final_cols = sorted_cols + [target_col]\n",
    "\n",
    "# Rearrange DataFrame\n",
    "df = df[final_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d158a",
   "metadata": {},
   "source": [
    "# SAVING CLEANED DATA TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a8ad1eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc593cc",
   "metadata": {},
   "source": [
    "# Read and Test datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5f8bcb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = pd.read_csv(\n",
    "    DATA_PATH, dtype=\"float32\"\n",
    ")  # Does not convert to float32 by default, dtype has to be explicitly provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "db954ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>education_level</th>\n",
       "      <th>income_level</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>alcohol_consumption_per_week</th>\n",
       "      <th>physical_activity_minutes_per_week</th>\n",
       "      <th>sleep_hours_per_day</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_postprandial</th>\n",
       "      <th>insulin_level</th>\n",
       "      <th>hba1c</th>\n",
       "      <th>diabetes_risk_score</th>\n",
       "      <th>diabetes_stage</th>\n",
       "      <th>diagnosed_diabetes</th>\n",
       "      <th>abdominal_obesity</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>activity_level</th>\n",
       "      <th>alcohol_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>6.36</td>\n",
       "      <td>8.18</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.63</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>5.07</td>\n",
       "      <td>7.51</td>\n",
       "      <td>44.700001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>253.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.200001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>12.74</td>\n",
       "      <td>7.20</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  ethnicity  education_level  income_level  employment_status  \\\n",
       "0  58.0     1.0        0.0              1.0           2.0                0.0   \n",
       "1  48.0     0.0        4.0              1.0           3.0                0.0   \n",
       "2  60.0     1.0        2.0              1.0           3.0                3.0   \n",
       "3  74.0     0.0        1.0              1.0           1.0                1.0   \n",
       "4  46.0     1.0        4.0              0.0           3.0                1.0   \n",
       "\n",
       "   smoking_status  alcohol_consumption_per_week  \\\n",
       "0             2.0                           0.0   \n",
       "1             1.0                           1.0   \n",
       "2             2.0                           1.0   \n",
       "3             2.0                           0.0   \n",
       "4             2.0                           1.0   \n",
       "\n",
       "   physical_activity_minutes_per_week  sleep_hours_per_day  ...  \\\n",
       "0                               215.0                  7.9  ...   \n",
       "1                               143.0                  6.5  ...   \n",
       "2                                57.0                 10.0  ...   \n",
       "3                                49.0                  6.6  ...   \n",
       "4                               109.0                  7.4  ...   \n",
       "\n",
       "   glucose_postprandial  insulin_level  hba1c  diabetes_risk_score  \\\n",
       "0                 236.0           6.36   8.18            29.600000   \n",
       "1                 150.0           2.00   5.63            23.000000   \n",
       "2                 195.0           5.07   7.51            44.700001   \n",
       "3                 253.0           5.28   9.03            38.200001   \n",
       "4                 184.0          12.74   7.20            23.500000   \n",
       "\n",
       "   diabetes_stage  diagnosed_diabetes  abdominal_obesity  bmi_group  \\\n",
       "0             4.0                 1.0                0.0        1.0   \n",
       "1             1.0                 0.0                0.0        0.0   \n",
       "2             4.0                 1.0                0.0        0.0   \n",
       "3             4.0                 1.0                1.0        2.0   \n",
       "4             4.0                 1.0                0.0        0.0   \n",
       "\n",
       "   activity_level  alcohol_group  \n",
       "0             0.0            1.0  \n",
       "1             2.0            1.0  \n",
       "2             1.0            1.0  \n",
       "3             1.0            1.0  \n",
       "4             2.0            1.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf62b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  float32\n",
      " 1   gender                              100000 non-null  float32\n",
      " 2   ethnicity                           100000 non-null  float32\n",
      " 3   education_level                     100000 non-null  float32\n",
      " 4   income_level                        100000 non-null  float32\n",
      " 5   employment_status                   100000 non-null  float32\n",
      " 6   smoking_status                      100000 non-null  float32\n",
      " 7   alcohol_consumption_per_week        100000 non-null  float32\n",
      " 8   physical_activity_minutes_per_week  100000 non-null  float32\n",
      " 9   sleep_hours_per_day                 100000 non-null  float32\n",
      " 10  screen_time_hours_per_day           100000 non-null  float32\n",
      " 11  family_history_diabetes             100000 non-null  float32\n",
      " 12  hypertension_history                100000 non-null  float32\n",
      " 13  cardiovascular_history              100000 non-null  float32\n",
      " 14  bmi                                 100000 non-null  float32\n",
      " 15  waist_to_hip_ratio                  100000 non-null  float32\n",
      " 16  systolic_bp                         100000 non-null  float32\n",
      " 17  diastolic_bp                        100000 non-null  float32\n",
      " 18  heart_rate                          100000 non-null  float32\n",
      " 19  cholesterol_total                   100000 non-null  float32\n",
      " 20  hdl_cholesterol                     100000 non-null  float32\n",
      " 21  ldl_cholesterol                     100000 non-null  float32\n",
      " 22  triglycerides                       100000 non-null  float32\n",
      " 23  glucose_fasting                     100000 non-null  float32\n",
      " 24  glucose_postprandial                100000 non-null  float32\n",
      " 25  insulin_level                       100000 non-null  float32\n",
      " 26  hba1c                               100000 non-null  float32\n",
      " 27  diabetes_risk_score                 100000 non-null  float32\n",
      " 28  diabetes_stage                      100000 non-null  float32\n",
      " 29  diagnosed_diabetes                  100000 non-null  float32\n",
      " 30  abdominal_obesity                   100000 non-null  float32\n",
      " 31  bmi_group                           100000 non-null  float32\n",
      " 32  activity_level                      100000 non-null  float32\n",
      " 33  alcohol_group                       100000 non-null  float32\n",
      "dtypes: float32(34)\n",
      "memory usage: 13.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dq.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997b2c7",
   "metadata": {},
   "source": [
    "# Creating DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41323816",
   "metadata": {},
   "source": [
    "### Clean Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(\n",
    "    df: pd.DataFrame, logger: Logger, extra_dropped_columns: Optional[List[str]] = None, show_dataframe_info = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Cleans the input DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to be cleaned.\n",
    "        logger (Logger): Logger object for logging information.\n",
    "        extra_dropped_columns (List[str], optional): Columns to drop from the features in original dataset.\n",
    "        show_dataframe_info (bool): Flag to toggle logging DataFrame info.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # Log the initial state of the DataFrame\n",
    "    logger.info(f\"Initial DataFrame shape: {df.shape}\")\n",
    "\n",
    "    if show_dataframe_info:\n",
    "        buffer = io.StringIO()  # Create a buffer to capture the info output\n",
    "        df.info(buf=buffer)  # Store the output into the buffer\n",
    "        logger.info(f\"Initial DataFrame info:\\n \" + buffer.getvalue())\n",
    "\n",
    "    # Drop any unused columns\n",
    "    try:\n",
    "        df.drop(columns=extra_dropped_columns, inplace=True)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Problem dropping columns:\\n{e}\")\n",
    "\n",
    "    # Replacing any entry data\n",
    "    df[\"alcohol_group\"] = df[\"alcohol_group\"].fillna(\"Light\")\n",
    "\n",
    "    # Create dictionaries for mapping/encoding\n",
    "\n",
    "    # ================================\n",
    "    # EXAMPLE PROCESS\n",
    "    # ================================\n",
    "\n",
    "    genders = sorted(df[\"gender\"].unique().tolist())\n",
    "    gender_dict = {gender: float(idx) for idx, gender in enumerate(genders)}\n",
    "\n",
    "    ethnicities = sorted(df[\"ethnicity\"].unique().tolist())\n",
    "    ethnicity_dict = {ethnicity: float(idx) for idx, ethnicity in enumerate(ethnicities)}\n",
    "\n",
    "    education_levels = sorted(df[\"education_level\"].unique().tolist())\n",
    "    education_level_dict = {education_level: float(idx) for idx, education_level in enumerate(education_levels)}\n",
    "\n",
    "    income_levels = sorted(df[\"income_level\"].unique().tolist())\n",
    "    income_level_dict = {income_level: float(idx) for idx, income_level in enumerate(income_levels)}\n",
    "\n",
    "    employment_statuses = sorted(df[\"employment_status\"].unique().tolist())\n",
    "\n",
    "    employment_status_dict = {employment_status: float(idx) for idx, employment_status in enumerate(employment_statuses)}\n",
    "\n",
    "    smoking_statuses = sorted(df[\"smoking_status\"].unique().tolist())\n",
    "\n",
    "    smoking_status_dict = {smoking_status: float(idx) for idx, smoking_status in enumerate(smoking_statuses)}\n",
    "\n",
    "    diabetes_stages = sorted(df[\"diabetes_stage\"].unique().tolist())\n",
    "    diabetes_stage_dict = {diabetes_stage: float(idx) for idx, diabetes_stage in enumerate(diabetes_stages)}\n",
    "\n",
    "    bmi_groups = sorted(df[\"bmi_group\"].unique().tolist())\n",
    "    bmi_group_dict = {bmi_group: float(idx) for idx, bmi_group in enumerate(bmi_groups)}\n",
    "\n",
    "    activity_levels = sorted(df[\"activity_level\"].unique().tolist())\n",
    "    activity_level_dict = {activity_level: float(idx) for idx, activity_level in enumerate(activity_levels)}\n",
    "\n",
    "    alcohol_groups = sorted(df[\"alcohol_group\"].unique().tolist())\n",
    "    alcohol_group_dict = {alcohol_group: float(idx) for idx, alcohol_group in enumerate(alcohol_groups)}\n",
    "\n",
    "    logger.info(\"Encoding categorical variables...\")\n",
    "    try:\n",
    "        df[\"gender\"] = df[\"gender\"].map(gender_dict)\n",
    "        df[\"ethnicity\"] = df[\"ethnicity\"].map(ethnicity_dict)\n",
    "        df[\"education_level\"] = df[\"education_level\"].map(education_level_dict)\n",
    "        df[\"income_level\"] = df[\"income_level\"].map(income_level_dict)\n",
    "        df[\"employment_status\"] = df[\"employment_status\"].map(employment_status_dict)\n",
    "        df[\"smoking_status\"] = df[\"smoking_status\"].map(smoking_status_dict)\n",
    "        df[\"diabetes_stage\"] = df[\"diabetes_stage\"].map(diabetes_stage_dict)\n",
    "        df[\"bmi_group\"] = df[\"bmi_group\"].map(bmi_group_dict)\n",
    "        df[\"activity_level\"] = df[\"activity_level\"].map(activity_level_dict)\n",
    "        df[\"alcohol_group\"] = df[\"alcohol_group\"].map(alcohol_group_dict)\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Problem encoding columns, {e}\")\n",
    "\n",
    "    # ================================\n",
    "    # END OF MAPPING/ENCODING EXAMPLE\n",
    "    # ================================\n",
    "\n",
    "    # Handle missing values (if any)\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        logger.info(\"Handling missing values...\")\n",
    "        df = df.dropna()  # Example: Drop rows with missing values\n",
    "        logger.info(f\"DataFrame shape after dropping missing values: {df.shape}\")\n",
    "\n",
    "    # Convert to 'float32' to reduce memory usage\n",
    "    logger.info(\"Converting Entire Data Frame to 'float32'...\")\n",
    "    df = df.astype(\"float32\")\n",
    "\n",
    "    if show_dataframe_info:\n",
    "        # Reinitialize the buffer to clear any previous content in order to log the final dataframe info\n",
    "        buffer = io.StringIO()\n",
    "        df.info(buf=buffer)\n",
    "        logger.info(f\"Final DataFrame info:\\n \" + buffer.getvalue())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c86fb",
   "metadata": {},
   "source": [
    "### Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd3fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Dataset class For the Custom Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file: str = \"../Data/DataSplits/test.csv\", label_column: str = \"Label\"):\n",
    "        \"\"\"Initializer for the Dataset class.\n",
    "\n",
    "        Args:\n",
    "            csv_file (str): Path to the CSV file containing the dataset.\n",
    "            label_column (str): The name of the column indicating the label.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.data = pd.read_csv(csv_file)  # Assign a pandas data frame\n",
    "        except FileNotFoundError:  # Raise an error if the file is not found\n",
    "            raise FileNotFoundError(f\"File not found: {csv_file}\")\n",
    "\n",
    "        # Define feature and label columns\n",
    "        self.label_column = label_column\n",
    "        # Omit the label column to create the list of feature columns\n",
    "        self.feature_columns = self.data.columns.drop([self.label_column])\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Returns a tuple (features, label) for the given index.\n",
    "\n",
    "        Args:\n",
    "            index (int): Index of the data sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (features, label) where features is a tensor of input features and label is the corresponding label.\n",
    "        \"\"\"\n",
    "        # Use 'iloc' instead of 'loc' for efficiency\n",
    "        features = self.data.iloc[index][self.feature_columns].values\n",
    "        label = self.data.iloc[index][self.label_column]  # Extract the label for the given index\n",
    "        return (torch.tensor(features, dtype=torch.float32), torch.tensor(label, dtype=torch.long))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the amount of samples in the dataset.\"\"\"\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c267da",
   "metadata": {},
   "source": [
    "### Data Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df05a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(\n",
    "    logger: Logger,\n",
    "    dataset_url: str,\n",
    "    root_data_dir: str = \"../Data\",\n",
    "    data_file_path: str = \"Dataset.csv\",\n",
    "    data_splits_dir: str = \"DataSplits\",\n",
    "    scaler_dir=\"Scalers\",\n",
    "    target_column: str = \"Target\",\n",
    "    use_label_scaler: bool = False,  # TOGGLE IF NEEDED\n",
    "    extra_dropped_columns: Optional[List[str]] = None,\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 0,\n",
    "    pin_memory: bool = False,\n",
    "    drop_last: bool = True,\n",
    ") -> tuple[\n",
    "    Dataset, Dataset, Dataset, DataLoader, DataLoader, DataLoader, MinMaxScaler, MinMaxScaler\n",
    "]:\n",
    "    \"\"\"This function prepares the train, test, and validation datasets.\n",
    "\n",
    "    Args:\n",
    "        logger (Logger): The logger instance to log messages.\n",
    "        dataset_url (str): The URL to download the dataset from, if not found locally.\n",
    "        root_data_dir (str): The root of the Data Directory\n",
    "        data_file_path (str): The name of the original dataset (with .csv file extension).\n",
    "        data_splits_dir (str): Path to the train, test, and validation datasets.\n",
    "        scaler_dir (str): Path to the feature and label scalers.\n",
    "        use_label_scaler (bool): Dictates whether to use label scaler\n",
    "        target_column (str): The name of the target column to predict.\n",
    "        extra_dropped_columns (List[str], optional): Columns to drop from the features in original dataset.\n",
    "        batch_size (int): The dataloader's batch_size.\n",
    "        num_workers (int): The dataloader's number of workers.\n",
    "        pin_memory (bool): The dataloader's pin memory option.\n",
    "        drop_last (bool): The dataloader's drop_last option.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset (Dataset): Dataset Class for the training dataset.\n",
    "        test_dataset (Dataset): Dataset Class for the test dataset.\n",
    "        validation_dataset (Dataset): Dataset Class for the validation dataset.\n",
    "        train_dataloader (DataLoader): The train dataloader.\n",
    "        test_dataloader (DataLoader): The test dataloader.\n",
    "        validation_dataloader (DataLoader): The validation dataloader.\n",
    "        feature_scaler (MinMaxScaler): The scaler used to scale the features of the model input.\n",
    "        label_scaler (MinMaxScaler): The scaler used to scale the labels of the model input.\n",
    "    \"\"\"\n",
    "    if (\n",
    "        not root_data_dir or not data_file_path or not data_splits_dir\n",
    "    ):  # Check for empty strings at the beginning\n",
    "        raise ValueError(\"File and directory paths cannot be empty strings.\")\n",
    "    DATA_ROOT = Path(root_data_dir)\n",
    "\n",
    "    DATA_CLEAN_PATH = DATA_ROOT / data_file_path  # Set the path to the complete dataset\n",
    "\n",
    "    if DATA_CLEAN_PATH.exists():\n",
    "        logger.info(f\"CSV file detected, reading from '{DATA_ROOT}'\")\n",
    "        df = pd.read_csv(\n",
    "            DATA_CLEAN_PATH, dtype=\"float32\"\n",
    "        )  # Convert data to float32 instead of, float64\n",
    "    else:\n",
    "        logger.info(f\"Downloading CSV file from '{dataset_url}'\\nand saving into '{DATA_ROOT}'\")\n",
    "        try:\n",
    "            os.makedirs(DATA_ROOT, exist_ok=True)  # Create the Data Root Directory\n",
    "            # Download and read the data into a pandas dataframe\n",
    "            df = pd.read_csv(dataset_url)  # Keep data as is, may not be able to expect float32 data\n",
    "\n",
    "            # Clean the data before saving\n",
    "            try:\n",
    "                df = clean_data(df, logger, extra_dropped_columns=extra_dropped_columns)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"An unexpected error occurred cleaning the dataset:\\n{e}\")\n",
    "\n",
    "            df.to_csv(DATA_CLEAN_PATH, index=False)  # Save the file, omitting saving the row index\n",
    "        except OSError as e:\n",
    "            raise RuntimeError(f\"OS error occurred: {e}\")\n",
    "        except ParserError:\n",
    "            raise RuntimeError(f\"Failed to parse CSV from '{dataset_url}'\")\n",
    "        except ValueError as e:\n",
    "            raise RuntimeError(f\"Data cleaning error:\\n{e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"An unexpected error occurred when downloading or saving the \"\n",
    "                f\"dataset from '{dataset_url}' to '{DATA_CLEAN_PATH}':\\n{e}\"\n",
    "            )\n",
    "\n",
    "    # Define the paths for the data splits and scalers\n",
    "    DATA_SPLITS_DIR = DATA_ROOT / data_splits_dir\n",
    "    SCALER_DIR = DATA_ROOT / scaler_dir\n",
    "\n",
    "    TRAIN_DATA_PATH = DATA_SPLITS_DIR / \"train.csv\"\n",
    "    TEST_DATA_PATH = DATA_SPLITS_DIR / \"test.csv\"\n",
    "    VALIDATION_DATA_PATH = DATA_SPLITS_DIR / \"val.csv\"\n",
    "\n",
    "    FEATURE_SCALER_PATH = SCALER_DIR / \"feature-scaler.joblib\"\n",
    "    LABEL_SCALER_PATH = SCALER_DIR / \"label-scaler.joblib\"\n",
    "\n",
    "    # Define the columns to drop from the features\n",
    "    columns_to_drop = [target_column]\n",
    "\n",
    "    # Define the Data Splits\n",
    "    TRAIN_SPLIT_PERCENTAGE = 0.9\n",
    "    VALIDATION_SPLIT_PERCENTAGE = 0.5\n",
    "\n",
    "    if (\n",
    "        os.path.exists(TRAIN_DATA_PATH)\n",
    "        and os.path.exists(TEST_DATA_PATH)\n",
    "        and os.path.exists(VALIDATION_DATA_PATH)\n",
    "    ):\n",
    "        logger.info(\n",
    "            f\"Train, Test, and Validation CSV datasets detected in '{DATA_SPLITS_DIR}.' Skipping generation and loading scaler(s)\"\n",
    "        )\n",
    "        try:\n",
    "            feature_scaler = joblib.load(FEATURE_SCALER_PATH)\n",
    "            logger.info(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "            if use_label_scaler:\n",
    "                joblib.dump(\n",
    "                    label_scaler, LABEL_SCALER_PATH\n",
    "                )  # Not used for this classification task\n",
    "                logger.info(f\"Label scaler stored in: ({LABEL_SCALER_PATH})\")\n",
    "            else:\n",
    "                label_scaler = None  # Omit the label scaler loading\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            raise RuntimeError(f\"Scaler file not found: {e}\")\n",
    "        except EOFError as e:\n",
    "            raise RuntimeError(f\"Scaler file appears to be empty or corrupted: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when loading scalers: {e}\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Datasets not found in '{DATA_SPLITS_DIR}' or incomplete. Generating datasets...\"\n",
    "        )\n",
    "        os.makedirs(DATA_SPLITS_DIR, exist_ok=True)  # Create the Data Splits Parent Directory\n",
    "        os.makedirs(SCALER_DIR, exist_ok=True)  # Create the Scaler Parent Directory\n",
    "\n",
    "        # Create the scaler objects\n",
    "        feature_scaler = MinMaxScaler()\n",
    "        if use_label_scaler:\n",
    "            label_scaler = MinMaxScaler()\n",
    "        else:\n",
    "            label_scaler = None  # Not used for this Classification task\n",
    "\n",
    "        try:\n",
    "            df_features = df.drop(columns=columns_to_drop, inplace=False)\n",
    "            df_labels = df[\n",
    "                [target_column]\n",
    "            ]  # Instead of returning a pandas Series using \"[]\", return a dataframe using the \"[[]]\" to get a shape with (-1,1)\n",
    "        except KeyError as e:\n",
    "            raise KeyError(\n",
    "                f\"One or more specified columns to drop do not exist in the DataFrame: {e}\"\n",
    "            )\n",
    "\n",
    "        # ================================\n",
    "        # ADD OVERSAMPLING AND OTHER DATA BALANCING TECHNIQUES HERE\n",
    "        # ================================\n",
    "\n",
    "        # Example of using OverSampling Technique to Balance out the Dataset for an Unbalanced Dataset\n",
    "        ros = RandomOverSampler(random_state=42)\n",
    "        df_features_resampled, df_labels_resampled = ros.fit_resample(df_features, df_labels)\n",
    "\n",
    "        # Split into smaller DataFrames for the Train, Test, and Validation splits\n",
    "        X_train, X_inter, Y_train, Y_inter = train_test_split(\n",
    "            df_features_resampled,\n",
    "            df_labels_resampled,\n",
    "            test_size=1 - TRAIN_SPLIT_PERCENTAGE,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        # ================================\n",
    "        # END  OF OVERSAMPLING AND OTHER DATA BALANCING TECHNIQUES ; OTHERWISE\n",
    "        # ================================\n",
    "\n",
    "        # Split into smaller DataFrames for the Train, Test, and Validation splits\n",
    "        X_train, X_inter, Y_train, Y_inter = train_test_split(\n",
    "            df_features,\n",
    "            df_labels,\n",
    "            test_size=1 - TRAIN_SPLIT_PERCENTAGE,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        X_validation, X_test, Y_validation, Y_test = train_test_split(\n",
    "            X_inter, Y_inter, test_size=1 - VALIDATION_SPLIT_PERCENTAGE, random_state=42\n",
    "        )\n",
    "\n",
    "        # Fit the scalers to the data\n",
    "        feature_scaler.fit(X_train)\n",
    "        # Only scale the labels if required\n",
    "        if use_label_scaler:\n",
    "            label_scaler.fit(Y_train)  # Not used for this Classification task\n",
    "\n",
    "        # Save the fitted scaler object\n",
    "        try:\n",
    "            joblib.dump(feature_scaler, FEATURE_SCALER_PATH)\n",
    "            logger.info(f\"Feature scaler stored in: ({FEATURE_SCALER_PATH})\")\n",
    "            # Save the Label Scaler if utilized\n",
    "            if use_label_scaler:\n",
    "                joblib.dump(\n",
    "                    label_scaler, LABEL_SCALER_PATH\n",
    "                )  # Not used for this Classification task\n",
    "                logger.info(f\"Label scaler stored in: ({LABEL_SCALER_PATH})\")\n",
    "        except FileNotFoundError as e:\n",
    "            raise RuntimeError(f\"Save path not found: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An unexpected error occurred when saving  Scaler(s): {e}\")\n",
    "\n",
    "        # Scale all Feature Inputs\n",
    "        X_train_scaled = feature_scaler.transform(X_train)\n",
    "        X_validation_scaled = feature_scaler.transform(X_validation)\n",
    "        X_test_scaled = feature_scaler.transform(X_test)\n",
    "\n",
    "        if use_label_scaler:  # HANDLE EACH ON A CASE BY CASE BASIS\n",
    "            Y_train = label_scaler.transform(Y_train)\n",
    "            Y_validation = label_scaler.transform(Y_validation)\n",
    "            Y_test = label_scaler.transform(Y_test)\n",
    "\n",
    "        logger.info(f\"Train Features (Scaled) Shape: {X_train_scaled.shape}\")\n",
    "        logger.info(f\"Validation Features (Scaled) Shape: {X_validation_scaled.shape}\")\n",
    "        logger.info(f\"Test Features (Scaled) Shape: {X_test_scaled.shape}\")\n",
    "\n",
    "        if use_label_scaler:\n",
    "            logger.info(f\"Train Labels (Scaled) Shape: {Y_train.shape}\")\n",
    "            logger.info(f\"Validation Labels (Scaled) Shape: {Y_validation.shape}\")\n",
    "            logger.info(f\"Test Labels (Scaled) Shape: {Y_test.shape}\")\n",
    "        else:\n",
    "            logger.info(f\"Train Labels Shape: {Y_train.shape}\")\n",
    "            logger.info(f\"Validation Labels Shape: {Y_validation.shape}\")\n",
    "            logger.info(f\"Test Labels Shape: {Y_test.shape}\")\n",
    "\n",
    "        # Define the column names of the features and label\n",
    "        features_names = df_features.columns\n",
    "        label_name = df_labels.columns\n",
    "\n",
    "        # Create dataframes using the scaled data\n",
    "        X_train_df = pd.DataFrame(X_train_scaled, columns=features_names)\n",
    "        X_test_df = pd.DataFrame(X_test_scaled, columns=features_names)\n",
    "        X_validation_df = pd.DataFrame(X_validation_scaled, columns=features_names)\n",
    "        Y_train_df = pd.DataFrame(Y_train, columns=label_name)\n",
    "        Y_test_df = pd.DataFrame(Y_test, columns=label_name)\n",
    "        Y_validation_df = pd.DataFrame(Y_validation, columns=label_name)\n",
    "\n",
    "        # Concatenate the features and labels back into a single DataFrame for each set\n",
    "        train_data_frame = pd.concat([X_train_df, Y_train_df.reset_index(drop=True)], axis=1)\n",
    "        test_data_frame = pd.concat([X_test_df, Y_test_df.reset_index(drop=True)], axis=1)\n",
    "        validation_data_frame = pd.concat(\n",
    "            [X_validation_df, Y_validation_df.reset_index(drop=True)], axis=1\n",
    "        )\n",
    "\n",
    "        # Saving the split data to csv files\n",
    "        try:\n",
    "            train_data_frame.to_csv(TRAIN_DATA_PATH, index=False)\n",
    "            test_data_frame.to_csv(TEST_DATA_PATH, index=False)\n",
    "            validation_data_frame.to_csv(VALIDATION_DATA_PATH, index=False)\n",
    "        except FileNotFoundError as e:\n",
    "            raise RuntimeError(f\"Save path not found: {e}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"An unexpected error occurred when saving datasets to CSV files:\\n{e}\"\n",
    "            )\n",
    "\n",
    "    # Creating Datasets from the stored datasets\n",
    "    logger.info(f\"INITIALIZING DATASETS\")\n",
    "    train_dataset = CustomDataset(csv_file=TRAIN_DATA_PATH, label_column=target_column)\n",
    "    test_dataset = CustomDataset(csv_file=TEST_DATA_PATH, label_column=target_column)\n",
    "    val_dataset = CustomDataset(csv_file=VALIDATION_DATA_PATH, label_column=target_column)\n",
    "\n",
    "    logger.info(\n",
    "        f\"Creating DataLoaders with 'batch_size'=({batch_size}), 'num_workers'=({num_workers}), 'pin_memory'=({pin_memory}). Training dataset 'drop_last'=({drop_last})\"\n",
    "    )\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    validation_dataloader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Training DataLoader has ({len(train_dataloader)}) batches, Test DataLoader has ({len(test_dataloader)}) batches, Validation DataLoader has ({len(validation_dataloader)}) batches\"\n",
    "    )\n",
    "\n",
    "    logger.info(\"==================================================================\")\n",
    "    for name, dataloader in [\n",
    "        (\"Train\", train_dataloader),\n",
    "        (\"Validation\", validation_dataloader),\n",
    "        (\"Test\", test_dataloader),\n",
    "    ]:\n",
    "        features, labels = next(iter(dataloader))  # Get one batch\n",
    "\n",
    "        logger.info(f\"{name} Dataloader Batch Information\")\n",
    "        logger.info(f\"Features Shape: '{features.shape}' |  DataTypes: '{features.dtype}'\")\n",
    "        logger.info(f\"Labels Shape: '{labels.shape}'   |  DataTypes: '{labels.dtype}' \")\n",
    "        logger.info(\"==================================================================\")\n",
    "\n",
    "    return (\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        val_dataset,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        feature_scaler,\n",
    "        label_scaler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6b97a",
   "metadata": {},
   "source": [
    "# Testing the Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c166aa6",
   "metadata": {},
   "source": [
    "## Testing with a given URL\n",
    "\n",
    "- Edit the Python dictionary 'data' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1a6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED WHEN TESTING THE RAW DATASET\n",
    "def test_data_pipeline():\n",
    "    # Function input setup\n",
    "    data = {\n",
    "        \"dataset_url\": \"hf://datasets/MaxPrestige/Synthetic-Diabetes-Dataset/Data/Synthetic-Diabetes-Dataset.csv\",\n",
    "        \"root_data_dir\": \"../Data\",\n",
    "        \"data_file_path\": DATA_CLEAN_FILE_NAME,\n",
    "        \"data_splits_dir\": \"DataSplits\",\n",
    "        \"scaler_dir\": \"Scalers\",\n",
    "        \"target_column\": \"diagnosed_diabetes\",\n",
    "        \"extra_dropped_columns\": [\n",
    "            # REPLACE WITH ANY COLUMNS TO BE EXCLUDED FROM THE DATASET - COMMA SEPARATED\n",
    "            \n",
    "        ],\n",
    "    }\n",
    "    batch_size = 64\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "    drop_last = True\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Call the data pipeline function\n",
    "    try:\n",
    "        (\n",
    "            train_dataset,\n",
    "            test_dataset,\n",
    "            val_dataset,\n",
    "            train_dataloader,\n",
    "            test_dataloader,\n",
    "            validation_dataloader,\n",
    "            feature_scaler,\n",
    "            label_scaler,\n",
    "        ) = data_pipeline(\n",
    "            logger,\n",
    "            **data,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=pin_memory,\n",
    "            drop_last=drop_last,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.info(f\"Caught Exception: {e}\", stack_info=True)\n",
    "\n",
    "    # Basic assertions to verify the outputs\n",
    "    assert isinstance(train_dataset, Dataset), \"train_dataset is not an instance of Dataset\"\n",
    "    assert isinstance(test_dataset, Dataset), \"test_dataset is not an instance of Dataset\"\n",
    "    assert isinstance(val_dataset, Dataset), \"val_dataset is not an instance of Dataset\"\n",
    "    assert isinstance(\n",
    "        train_dataloader, DataLoader\n",
    "    ), \"train_dataloader is not an instance of DataLoader\"\n",
    "    assert isinstance(\n",
    "        test_dataloader, DataLoader\n",
    "    ), \"test_dataloader is not an instance of DataLoader\"\n",
    "    assert isinstance(\n",
    "        validation_dataloader, DataLoader\n",
    "    ), \"validation_dataloader is not an instance of DataLoader\"\n",
    "    assert isinstance(\n",
    "        feature_scaler, MinMaxScaler\n",
    "    ), \"feature_scaler is not an instance of MinMaxScaler\"\n",
    "    # assert isinstance(label_scaler, MinMaxScaler), \"label_scaler is not an instance of MinMaxScaler\"\n",
    "\n",
    "    logger.info(\"All assertions passed. Data pipeline test successful.\")\n",
    "\n",
    "    return (\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        val_dataset,\n",
    "        train_dataloader,\n",
    "        test_dataloader,\n",
    "        validation_dataloader,\n",
    "        feature_scaler,\n",
    "        label_scaler,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d571ecb",
   "metadata": {},
   "source": [
    "### Call the 'test_data_pipeline' function and capture the return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a32677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Downloading CSV file from 'hf://datasets/MaxPrestige/Synthetic-Diabetes-Dataset/Data/Synthetic-Diabetes-Dataset.csv'\n",
      "and saving into '..\\Data'\n",
      "INFO:__main__:Initial DataFrame shape: (100000, 34)\n",
      "INFO:__main__:Initial DataFrame info:\n",
      " <class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  int64  \n",
      " 1   gender                              100000 non-null  object \n",
      " 2   ethnicity                           100000 non-null  object \n",
      " 3   education_level                     100000 non-null  object \n",
      " 4   income_level                        100000 non-null  object \n",
      " 5   employment_status                   100000 non-null  object \n",
      " 6   smoking_status                      100000 non-null  object \n",
      " 7   alcohol_consumption_per_week        100000 non-null  int64  \n",
      " 8   physical_activity_minutes_per_week  100000 non-null  int64  \n",
      " 9   sleep_hours_per_day                 100000 non-null  float64\n",
      " 10  screen_time_hours_per_day           100000 non-null  float64\n",
      " 11  family_history_diabetes             100000 non-null  int64  \n",
      " 12  hypertension_history                100000 non-null  int64  \n",
      " 13  cardiovascular_history              100000 non-null  int64  \n",
      " 14  bmi                                 100000 non-null  float64\n",
      " 15  waist_to_hip_ratio                  100000 non-null  float64\n",
      " 16  systolic_bp                         100000 non-null  int64  \n",
      " 17  diastolic_bp                        100000 non-null  int64  \n",
      " 18  heart_rate                          100000 non-null  int64  \n",
      " 19  cholesterol_total                   100000 non-null  int64  \n",
      " 20  hdl_cholesterol                     100000 non-null  int64  \n",
      " 21  ldl_cholesterol                     100000 non-null  int64  \n",
      " 22  triglycerides                       100000 non-null  int64  \n",
      " 23  glucose_fasting                     100000 non-null  int64  \n",
      " 24  glucose_postprandial                100000 non-null  int64  \n",
      " 25  insulin_level                       100000 non-null  float64\n",
      " 26  hba1c                               100000 non-null  float64\n",
      " 27  diabetes_risk_score                 100000 non-null  float64\n",
      " 28  diabetes_stage                      100000 non-null  object \n",
      " 29  diagnosed_diabetes                  100000 non-null  int64  \n",
      " 30  abdominal_obesity                   100000 non-null  int64  \n",
      " 31  bmi_group                           100000 non-null  object \n",
      " 32  activity_level                      100000 non-null  object \n",
      " 33  alcohol_group                       86465 non-null   object \n",
      "dtypes: float64(7), int64(17), object(10)\n",
      "memory usage: 25.9+ MB\n",
      "\n",
      "INFO:__main__:Encoding categorical variables...\n",
      "INFO:__main__:Converting Entire Data Frame to 'float32'...\n",
      "INFO:__main__:Final DataFrame info:\n",
      " <class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 34 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   age                                 100000 non-null  float32\n",
      " 1   gender                              100000 non-null  float32\n",
      " 2   ethnicity                           100000 non-null  float32\n",
      " 3   education_level                     100000 non-null  float32\n",
      " 4   income_level                        100000 non-null  float32\n",
      " 5   employment_status                   100000 non-null  float32\n",
      " 6   smoking_status                      100000 non-null  float32\n",
      " 7   alcohol_consumption_per_week        100000 non-null  float32\n",
      " 8   physical_activity_minutes_per_week  100000 non-null  float32\n",
      " 9   sleep_hours_per_day                 100000 non-null  float32\n",
      " 10  screen_time_hours_per_day           100000 non-null  float32\n",
      " 11  family_history_diabetes             100000 non-null  float32\n",
      " 12  hypertension_history                100000 non-null  float32\n",
      " 13  cardiovascular_history              100000 non-null  float32\n",
      " 14  bmi                                 100000 non-null  float32\n",
      " 15  waist_to_hip_ratio                  100000 non-null  float32\n",
      " 16  systolic_bp                         100000 non-null  float32\n",
      " 17  diastolic_bp                        100000 non-null  float32\n",
      " 18  heart_rate                          100000 non-null  float32\n",
      " 19  cholesterol_total                   100000 non-null  float32\n",
      " 20  hdl_cholesterol                     100000 non-null  float32\n",
      " 21  ldl_cholesterol                     100000 non-null  float32\n",
      " 22  triglycerides                       100000 non-null  float32\n",
      " 23  glucose_fasting                     100000 non-null  float32\n",
      " 24  glucose_postprandial                100000 non-null  float32\n",
      " 25  insulin_level                       100000 non-null  float32\n",
      " 26  hba1c                               100000 non-null  float32\n",
      " 27  diabetes_risk_score                 100000 non-null  float32\n",
      " 28  diabetes_stage                      100000 non-null  float32\n",
      " 29  diagnosed_diabetes                  100000 non-null  float32\n",
      " 30  abdominal_obesity                   100000 non-null  float32\n",
      " 31  bmi_group                           100000 non-null  float32\n",
      " 32  activity_level                      100000 non-null  float32\n",
      " 33  alcohol_group                       100000 non-null  float32\n",
      "dtypes: float32(34)\n",
      "memory usage: 13.0 MB\n",
      "\n",
      "INFO:__main__:Datasets not found in '..\\Data\\DataSplits' or incomplete. Generating datasets...\n",
      "INFO:__main__:Feature scaler stored in: (..\\Data\\Scalers\\feature-scaler.joblib)\n",
      "INFO:__main__:Train Features (Scaled) Shape: (90000, 33)\n",
      "INFO:__main__:Validation Features (Scaled) Shape: (5000, 33)\n",
      "INFO:__main__:Test Features (Scaled) Shape: (5000, 33)\n",
      "INFO:__main__:Train Labels Shape: (90000, 1)\n",
      "INFO:__main__:Validation Labels Shape: (5000, 1)\n",
      "INFO:__main__:Test Labels Shape: (5000, 1)\n",
      "INFO:__main__:INITIALIZING DATASETS\n",
      "INFO:__main__:Creating DataLoaders with 'batch_size'=(64), 'num_workers'=(0), 'pin_memory'=(False). Training dataset 'drop_last'=(True)\n",
      "INFO:__main__:Training DataLoader has (1406) batches, Test DataLoader has (78) batches, Validation DataLoader has (78) batches\n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Train Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Validation Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Test Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:All assertions passed. Data pipeline test successful.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    val_dataset,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    validation_dataloader,\n",
    "    feature_scaler,\n",
    "    label_scaler,\n",
    ") = test_data_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72575b66",
   "metadata": {},
   "source": [
    "### Verify the length of the dataloader(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c5eda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd10c7",
   "metadata": {},
   "source": [
    "### See details about a batch of each dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd10b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Train Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:The labels: tensor([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1])\n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Validation Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:The labels: tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0])\n",
      "INFO:__main__:==================================================================\n",
      "INFO:__main__:Test Dataloader Batch Information\n",
      "INFO:__main__:Features Shape: 'torch.Size([64, 33])' |  DataTypes: 'torch.float32'\n",
      "INFO:__main__:Labels Shape: 'torch.Size([64])'   |  DataTypes: 'torch.int64' \n",
      "INFO:__main__:The labels: tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1])\n",
      "INFO:__main__:==================================================================\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"==================================================================\")\n",
    "for name, dataloader in [\n",
    "    (\"Train\", train_dataloader),\n",
    "    (\"Validation\", validation_dataloader),\n",
    "    (\"Test\", test_dataloader),\n",
    "]:\n",
    "    features, labels = next(iter(dataloader))  # Get one batch\n",
    "\n",
    "    logger.info(f\"{name} Dataloader Batch Information\")\n",
    "    logger.info(f\"Features Shape: '{features.shape}' |  DataTypes: '{features.dtype}'\")\n",
    "    logger.info(f\"Labels Shape: '{labels.shape}'   |  DataTypes: '{labels.dtype}' \")\n",
    "    logger.info(f\"The labels: {labels}\")  # Optional\n",
    "    logger.info(\"==================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "type2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
